---
title: "Forecasting Inflation"
author: "Caitlin Brown"
date: "`r format(Sys.Date(),'%B %d, %Y')`"
output:
  html_document:
    df_print: paged
    code_folding: hide
    toc: no
    fig_caption: yes
    theme: cerulean
    toc_float: no
    pdf_document: default
---

```{r setup, include = FALSE}
rm(list=ls())
graphics.off()
knitr::opts_chunk$set(echo=TRUE, message=FALSE, warning=FALSE)
```
Inflation is known as the rate of increase in prices over a given period of time, it is a broad measure of the cost of living in a country and overall increase in prices.

The goal of this study will be to forecast inflation over a 12 month period with the help of five variables obtained from the Federal Reserve Economic Database (FRED), and compare the efficiency of the variables involved. Estimating the Phillips Curve model as a baseline($m1$), then estimating three additional models ($(m1, m2, m3)$). Where ($u_t$) is replaced with one of my assigned variables ($x_t$), which will be transformed to be stationary (so that variance, and autocorrelation structure do not change over time). ($u_t$) in this study represents annualized unemployment rate which is captured by `UNRATE`. We will use 12 lags (the fixed amount of passing time for a time series) for both variables and finally estimate an ensemble model ($me=m1+m2+m3+m4/4$) which is a fitted model of tne average of the four variables.
Each model is estimated over a training data set with observations through December 2018. We will also evaluate the out-of sample performance of our models using a testing data set with observations from January 2019 onward.
```{r loadPackages, message = FALSE}
require(fpp3)
require(tsibble)
require(tidyverse)
require(tidyquant)
require(lubridate)
require(timetk)
require(kableExtra)
require(reshape2)
require(ggplot2)
```

```{r UploadData, message=FALSE}
Variablelist<- c("PCEPI", "UNRATE", "MICH", "IPMAN", "EXPINF1YR")
x<- tq_get (Variablelist, get = "economic.data", from = "1982-01-01") %>%
    mutate(Date= yearmonth(date), value= price) %>%
    select(-c(date, price)) %>%
    as_tsibble(index = Date, key = symbol)
Xwide<- x %>%
    pivot_wider(names_from = symbol, values_from = value) %>%
    as_tsibble()
```
The Variable list includes `PCEPI`, Personal Consumption Expenditures: Chain-type Price Index, with units seasonally Adjusted and Index 2012=100. This indicator will be used to calculate inflation as it captures inflation across a variety of consumer expenses.

`UNRATE` is the Unemployment Rate, measured in percent and seasonally adjusted, this variable has a direct correlation with inflation. Inflation and unemployment are known to have a inverse relationship with a concave slope. As unemployment decreases, inflation increases. This is the result of a increase in labor demand which leads to an increases in prices of good in order for firms to offset increased wages.  

`MICH` is University of Michigan: Inflation Expectation, measured in percent and not seasonally adjusted. We assume this variable will hold an impact as it indicates the populations expectations of inflation and captures the effects of changes in behavior that stem from those expectations. 


`IPMAN` is Industrial Production: Manufacturing, measure is seasonally adjusted and index 2017=100. This variable could also be a significant indicator of inflation. As inflation increase the cost of raw materials of production, this can decrease the amount of aggregate production in the economy. If demand of goods remain unchanged then the price increase of production is deferred to consumers creating cost-push inflation.

The final variable in our list is `EXPINF1YR`, which is 1-Year Expected Inflation measured in percent and not seasonally adjusted. This variable is used for similarly like `MICH`, the expectations of inflation over 1 year is taken into account by firms and consumers purchasing behavior. 
```{r TransformingVariablesStationary, message=FALSE}
z <- Xwide %>% select(c(PCEPI, UNRATE, MICH, IPMAN, EXPINF1YR)) %>%
  mutate(infl = 1200*log(PCEPI/lag(PCEPI))) %>%
  mutate(dinfl = infl - lag(infl, 1)) %>%
  mutate(dinfl12 = 100*log(PCEPI/lag(PCEPI,12)) - lag(infl,12))%>%
  mutate(Unrate = UNRATE - lag(UNRATE))%>%
  mutate(Mich = 10*log(MICH/lag(MICH)))%>%
  mutate(Ipman = 1200*log(IPMAN/lag(IPMAN))) %>%
  mutate(Expinf1yr = EXPINF1YR - lag(EXPINF1YR)) %>%
  select(-c(PCEPI, UNRATE, MICH, IPMAN, EXPINF1YR)) %>% 
  drop_na()
  

train_data<- z %>% filter_index(~ "2018-12-01")
test_data<- z %>% filter_index("2019-01-01" ~ .)
```  
The below graphs is a rationality check to ensure units look reasonable, this is not necessarily pertinent to the client,
```{r Melt, False}
zm <- melt(z, "Date")
ggplot(zm, aes(Date, value)) + 
  geom_line() + 
  facet_wrap(~variable, scales = "free", ncol = 2)
```
The below section fits the baseline Phillips curve model to show the model specification using TSLM, the forecast is made using TSLM because this function fits linear models to time series including trend and seasonality components. We are not using ARIMA since we are specifying the lag models according to economic theory. From this we can gather the R-squared adjusted R-squared, the low p-value of our F-statistic indicates joint significance of our variables.

```{r m1Model, message=FALSE}
fitPhillipsc<- train_data %>%
  model(
    mPC = TSLM(dinfl12 ~ 1 +
                 lag(dinfl,12) + lag(dinfl, 13) + lag(dinfl,14) +
                 lag(dinfl,15) + lag(dinfl,16) + lag(dinfl,17)+
                 lag(dinfl,18) + lag(dinfl,19) + lag(dinfl,20)+
                 lag(dinfl,21) + lag(dinfl,22) + lag(dinfl,23)+
                 lag(Unrate,12) + lag(Unrate,13) + lag(Unrate,14)+
                 lag(Unrate,15) + lag(Unrate,16) + lag(Unrate,17)+
                 lag(Unrate,18) + lag(Unrate,19) + lag(Unrate,20)+
                 lag(Unrate,21) + lag(Unrate,22) + lag(Unrate,23)
               )
  )
report(fitPhillipsc)
```  
We estimate all four of our models over the training period within a single "fit" code block, we redefine the model using `MICH`, `IPHMAN`, `EXPINF1YR` for further comparison.

```{r m2m3m4Model, message=FALSE}
fitall <- train_data %>%
  model(
    mUNRATE= TSLM(dinfl12 ~ 1 +
                 lag(dinfl,12) + lag(dinfl,13) + lag(dinfl,14) +
                 lag(dinfl,15) + lag(dinfl,16) + lag(dinfl,17) +
                 lag(dinfl,18) + lag(dinfl,19) + lag(dinfl,20) +
                 lag(dinfl,21) + lag(dinfl,22) + lag(dinfl,23) +
                 lag(Unrate,12) + lag(Unrate,13) + lag(Unrate,14) +
                 lag(Unrate,15) + lag(Unrate,16) + lag(Unrate,17) +
                 lag(Unrate,18) + lag(Unrate,19) + lag(Unrate,20) +
                 lag(Unrate,21) + lag(Unrate,22) + lag(Unrate,23) 
                 ),
    mMICH= TSLM(dinfl12 ~ 1 +
                 lag(dinfl,12) + lag(dinfl,13) + lag(dinfl,14) +
                 lag(dinfl,15) + lag(dinfl,16) + lag(dinfl,17) +
                 lag(dinfl,18) + lag(dinfl,19) + lag(dinfl,20) +
                 lag(infl,21) + lag(dinfl,22) + lag(dinfl,23) +
                 lag(Mich,12) + lag(Mich,13) + lag(Mich,14) +
                 lag(Mich,15) + lag(Mich,16) + lag(Mich,17) +
                 lag(Mich,18) + lag(Mich,19) + lag(Mich,20) +
                 lag(Mich,21) + lag(Mich,22) + lag(Mich,23) 
                 ),
    mIPMAN= TSLM(dinfl12 ~ 1 +
                    lag(dinfl,12) + lag(dinfl,13) + lag(dinfl,14) +
                    lag(dinfl,15) + lag(dinfl,16) + lag(dinfl,17) +
                    lag(dinfl,18) + lag(dinfl,19) + lag(dinfl,20) +
                    lag(dinfl,21) + lag(dinfl,22) + lag(dinfl,23) +
                    lag(Ipman,12) + lag(Ipman,13)+ lag(Ipman,14) + lag(Ipman,15) +
                    lag(Ipman,16) + lag(Ipman,17) + lag(Ipman,18) + lag(Ipman,19) +
                    lag(Ipman,20) + lag(Ipman, 21) + lag(Ipman,22) + lag(Ipman,23)
                  ),
    mEXP = TSLM(dinfl12 ~ 1 +
                 lag(dinfl,12) + lag(dinfl,13) + lag(dinfl,14) +
                 lag(dinfl,15) + lag(dinfl,16) + lag(dinfl,17) +
                 lag(dinfl,18) + lag(dinfl,19) + lag(dinfl,20) +
                 lag(dinfl,21) + lag(dinfl,22) + lag(dinfl,23) +
                 lag(Expinf1yr,12) + lag(Expinf1yr,13) + lag(Expinf1yr,14) +
                 lag(Expinf1yr,15) + lag(Expinf1yr,16) + lag(Expinf1yr,17) +
                 lag(Expinf1yr,18) + lag(Expinf1yr,19) + lag(Expinf1yr,20) +
                 lag(Expinf1yr,21) + lag(Expinf1yr,22) + lag(Expinf1yr,23) 
                 ) 
  )
tidy(fitall)
```    
We also look at the accuracy of our models over the train data set. From this we can evaluate the measures that are of most interest RMSE (Root Mean Error squared) is a measurement the average difference between the values the forecast predicted, and the true values, 0 is a perfect fit. MAE (Mean Absolute Error) is a measure of errors between paired observations expressing the same phenomenon. MASE (Mean Absolute standard error) computes the mean absolute scaled error between two numeric vectors. As well as MAPE(Mean Absolute Percentage Error) the sum of the individual absolute errors divided by the demand, the average of the percentage errors. MAPE is commonly used because it is easy to interpret and explain and not scale-dependent so useful for forecast evaluation but also limited therefore we avoid it in this project. These measurements of accuracy and error determine how well the model fits the data.  
From this we gather none of the models fit the data very well but `MICH` has the lowest RMSE, MAE, MASE.
```{r Accuracy1, message=FALSE}
accuracy(fitall)
```
But this does not mean `MICH` is the best predictor because when evaluated we see that, below depicts the residuals of `MICH`. The acf shows we have serial correlation in the residuals,variation of residuals is not constant, and the left skew of the final graph indicates`MICH` does a poor fit.
```{r EvalmMICHAccuracy, message=FALSE}
fitall %>% select(mMICH) %>% report()
fitall %>% select(mMICH) %>% gg_tsresiduals()
```  
Then we fit the ensemble model as the simple average of our three individual models.
Forecasting all 5 models over the test data set. We plot the 5 forecasts on a single graph and report the accuracy of the 5 models over the train and test data sets as shown below. The black line  indicates inflation and the colored lines indicate our models.Just by eyeballing we clearly observe that the model of worst fit is mUNRATE as it has the highest MAE, MASE, and RMSSE, as well as the fact more volatile than any other forecast and more volatile than history suggests inflation should be.
```{r ComboModel, message=FALSE}
fitcombo <- fitall %>% mutate(combo = (mUNRATE + mMICH + mIPMAN + mEXP)/4)
```
```{r ComboGraph, message=FALSE}
forecastFit <- fitcombo%>% forecast(new_data = test_data)
forecastFit %>% autoplot(filter(z, year(Date) > 2016), level = c(95)) +
  labs(caption = "Time Series data taken from FRED database", aes(color = "hotpink")) + 
   labs(title = "Time Series Linear Model Forecast") +
  ylab("Inflation Rate (measured in percent)") +
  xlab("Month")
```

```{r ComaparedAccuracyInSample, message=FALSE }
accuracy(fitcombo)
```

```{r CompareAccuracyOutSample, message=FALSE}
accuracy(forecastFit, z)
```
  
  In conclusion, none of our models fit the very well,using MAE, MASE, and RMSSE as indicators of best fit for in sample and out of sample, the worst of all being UNRATE. But the tables above indicate that our combo model which averages all the models is the best choice, both in sample and out of sample, of forecasting inflation in the U.S.
















